{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library used and deeclare data needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from numpy.typing import NDArray\n",
    "from scipy.stats import zscore\n",
    "from pytictoc import TicToc\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold, PredefinedSplit\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_fcn = 'rbf'\n",
    "opts_csv_fold = 5\n",
    "with open('./data/algolabels.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            algo_labels = row\n",
    "\n",
    "y = pd.read_csv('./data/ybin.csv', header=None).values\n",
    "z = pd.read_csv('./data/z_M.csv', header=None, dtype=np.float64)\n",
    "\n",
    "ninst, nalgos = y.shape\n",
    "w = np.ones((ninst, nalgos))\n",
    "\n",
    "\"\"\" Problem 1 - Normalization generate different result with MATLAB \"\"\"\n",
    "z_norm = (z-np.mean(z, axis=0))/np.std(z, ddof=1, axis=0)\n",
    "pd.DataFrame(z_norm).to_csv('z_f.csv', header=None, index=None)\n",
    "# scaler = StandardScaler().fit(z)\n",
    "\n",
    "cvcmat = np.zeros((nalgos, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare k-fold data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   4   5  13  20  27  30  34  35  42  46  49  56  62  69  82  84\n",
      "  86  87  94  97 111 113 123 126 130 136 142 150 157 160 164 172 179 182\n",
      " 185 186 190 194 204 206]\n",
      "[  3   9  14  16  17  18  23  28  37  40  57  63  70  76  99 101 108 110\n",
      " 112 121 124 125 132 133 144 149 152 161 163 167 169 171 177 181 183 187\n",
      " 195 196 203 207 208 209 212]\n",
      "[ 10  21  24  26  41  45  53  54  55  58  61  64  65  67  73  74  77  83\n",
      "  85  92  93  96 102 103 107 122 127 128 129 138 140 141 154 159 173 174\n",
      " 175 180 188 189 193 197 205]\n",
      "[ 12  19  25  29  31  32  33  36  38  39  43  59  68  75  78  88  95  98\n",
      " 105 115 117 120 134 137 139 143 146 148 151 156 158 162 165 170 184 198\n",
      " 199 200 201 202 210 211]\n",
      "[  6   7   8  11  15  22  44  47  48  50  51  52  60  66  71  72  79  80\n",
      "  81  89  90  91 100 104 106 109 114 116 118 119 131 135 145 147 153 155\n",
      " 166 168 176 178 191 192]\n",
      "Fold 0:\n",
      "  Train: index=[  2   5   6   7   8   9  10  11  13  14  15  16  17  18  20  21  22  23\n",
      "  24  25  27  28  30  31  32  35  36  37  38  39  40  42  43  44  46  47\n",
      "  49  50  51  52  53  54  56  57  58  59  60  62  63  64  65  66  67  69\n",
      "  70  71  72  73  74  75  76  77  78  79  80  82  84  87  88  89  90  91\n",
      "  92  94  95  97  98  99 100 101 102 103 104 105 106 107 108 109 111 113\n",
      " 114 115 116 117 118 119 120 121 123 124 126 127 128 130 131 132 133 134\n",
      " 136 137 138 139 140 142 143 144 145 146 147 148 150 151 152 153 154 155\n",
      " 157 158 160 161 162 164 165 166 167 168 169 170 172 173 174 175 176 177\n",
      " 179 180 182 183 186 187 188 190 191 192 194 195 196 197 198 199 200 201\n",
      " 202 204 206 207 208 209 210 211]\n",
      "  Test:  index=[  0   1   3   4  12  19  26  29  33  34  41  45  48  55  61  68  81  83\n",
      "  85  86  93  96 110 112 122 125 129 135 141 149 156 159 163 171 178 181\n",
      " 184 185 189 193 203 205]\n",
      "Fold 1:\n",
      "  Train: index=[  0   1   3   4   5   6   7   9  10  11  12  14  18  19  20  21  23  24\n",
      "  25  26  28  29  30  31  32  33  34  35  37  38  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  55  57  58  59  60  61  63  64  65\n",
      "  66  67  68  70  71  72  73  74  76  77  78  79  80  81  82  83  84  85\n",
      "  86  87  88  89  90  91  92  93  94  95  96  97  99 101 102 103 104 105\n",
      " 106 108 110 112 113 114 115 116 117 118 119 121 122 125 126 127 128 129\n",
      " 130 133 134 135 136 137 138 139 140 141 142 144 145 146 147 149 150 152\n",
      " 153 154 155 156 157 158 159 161 163 164 165 167 169 171 172 173 174 175\n",
      " 177 178 179 181 183 184 185 187 188 189 190 191 192 193 196 197 198 199\n",
      " 200 201 203 204 205 209 210]\n",
      "  Test:  index=[  2   8  13  15  16  17  22  27  36  39  56  62  69  75  98 100 107 109\n",
      " 111 120 123 124 131 132 143 148 151 160 162 166 168 170 176 180 182 186\n",
      " 194 195 202 206 207 208 211]\n",
      "Fold 2:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8  10  11  12  13  14  15  16  17  18\n",
      "  19  21  22  24  26  27  28  29  30  31  32  33  34  35  36  37  38  39\n",
      "  41  42  43  45  46  47  48  49  50  51  55  56  58  59  61  62  65  67\n",
      "  68  69  70  71  74  75  77  78  79  80  81  83  85  86  87  88  89  90\n",
      "  93  94  96  97  98  99 100 103 104 105 107 108 109 110 111 112 113 114\n",
      " 115 116 117 118 119 120 122 123 124 125 129 130 131 132 133 134 135 136\n",
      " 138 141 142 143 144 145 146 147 148 149 150 151 152 154 155 156 157 159\n",
      " 160 161 162 163 164 165 166 167 168 169 170 171 175 176 177 178 180 181\n",
      " 182 183 184 185 186 189 190 191 193 194 195 197 198 199 200 201 202 203\n",
      " 205 206 207 208 209 210 211]\n",
      "  Test:  index=[  9  20  23  25  40  44  52  53  54  57  60  63  64  66  72  73  76  82\n",
      "  84  91  92  95 101 102 106 121 126 127 128 137 139 140 153 158 172 173\n",
      " 174 179 187 188 192 196 204]\n",
      "Fold 3:\n",
      "  Train: index=[  0   1   2   3   4   5   6   7   8   9  10  12  13  14  15  16  17  19\n",
      "  20  21  22  23  25  26  27  29  33  34  36  39  40  41  43  44  45  46\n",
      "  47  48  49  50  51  52  53  54  55  56  57  59  60  61  62  63  64  65\n",
      "  66  68  69  70  71  72  73  75  76  78  79  80  81  82  83  84  85  86\n",
      "  88  89  90  91  92  93  95  96  98  99 100 101 102 103 105 106 107 108\n",
      " 109 110 111 112 113 115 117 118 120 121 122 123 124 125 126 127 128 129\n",
      " 130 131 132 134 135 137 139 140 141 143 144 146 148 149 151 152 153 154\n",
      " 156 158 159 160 162 163 165 166 167 168 170 171 172 173 174 175 176 177\n",
      " 178 179 180 181 182 184 185 186 187 188 189 190 191 192 193 194 195 196\n",
      " 202 203 204 205 206 207 208 211]\n",
      "  Test:  index=[ 11  18  24  28  30  31  32  35  37  38  42  58  67  74  77  87  94  97\n",
      " 104 114 116 119 133 136 138 142 145 147 150 155 157 161 164 169 183 197\n",
      " 198 199 200 201 209 210]\n",
      "Fold 4:\n",
      "  Train: index=[  0   1   2   3   4   8   9  11  12  13  15  16  17  18  19  20  22  23\n",
      "  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41\n",
      "  42  44  45  48  52  53  54  55  56  57  58  60  61  62  63  64  66  67\n",
      "  68  69  72  73  74  75  76  77  81  82  83  84  85  86  87  91  92  93\n",
      "  94  95  96  97  98 100 101 102 104 106 107 109 110 111 112 114 116 119\n",
      " 120 121 122 123 124 125 126 127 128 129 131 132 133 135 136 137 138 139\n",
      " 140 141 142 143 145 147 148 149 150 151 153 155 156 157 158 159 160 161\n",
      " 162 163 164 166 168 169 170 171 172 173 174 176 178 179 180 181 182 183\n",
      " 184 185 186 187 188 189 192 193 194 195 196 197 198 199 200 201 202 203\n",
      " 204 205 206 207 208 209 210 211]\n",
      "  Test:  index=[  5   6   7  10  14  21  43  46  47  49  50  51  59  65  70  71  78  79\n",
      "  80  88  89  90  99 103 105 108 113 115 117 118 130 134 144 146 152 154\n",
      " 165 167 175 177 190 191]\n"
     ]
    }
   ],
   "source": [
    "# Read indices\n",
    "test_fold = np.full(212, -1)\n",
    "\n",
    "for i in range (opts_csv_fold):\n",
    "    csv_file = f'../tests/pythia/k-fold/A_2_test_indices_fold_{i + 1}.csv'\n",
    "    test_indices = pd.read_csv(csv_file, header=None).squeeze().values\n",
    "    print(test_indices)\n",
    "    \n",
    "    adjusted_test_indices = test_indices - 1\n",
    "    test_fold[adjusted_test_indices] = i\n",
    "\n",
    "# print(test_fold)\n",
    "\n",
    "ps = PredefinedSplit(test_fold)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(ps.split()):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C 3.0025887646926703\n",
      "Best gamma 0.14776528839878358\n",
      "[[ 59  25]\n",
      " [  8 120]]\n"
     ]
    }
   ],
   "source": [
    "# Grid Search on this set for the first algorithm\n",
    "y_b = y[:, 1]\n",
    "w_b = w[:, 1]\n",
    "\n",
    "z_norm = np.ascontiguousarray(z)\n",
    "y_b = np.ascontiguousarray(y_b)\n",
    "w_b = np.ascontiguousarray(w_b)\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.logspace(-10, 4, base=2, num=30),\n",
    "    'gamma': np.logspace(-10, 4, base=2, num=30)\n",
    "}\n",
    "# By default, the class_weight=None represent equal weight\n",
    "svm_model = SVC(kernel='rbf', class_weight=None, random_state=0)\n",
    "\n",
    "        # steps = list()\n",
    "        # steps.append(('scaler', StandardScaler()))\n",
    "        # steps.append(('model', svm_model))\n",
    "        # pipeline = Pipeline(steps=steps)\n",
    "\n",
    "        # Used for exhaustive search over specified parameter values for the SVM. The param_grid defines \n",
    "        # the range over which C and gamma will be tuned.\n",
    "        # GridSearchCV for optimizing the hyperparameters\n",
    "\n",
    "        # TODO different c and gamma, same k-fold\n",
    "        # Unaltimate \n",
    "grid_search = GridSearchCV(\n",
    "            svm_model, param_grid, \n",
    "            scoring='accuracy',\n",
    "            cv=ps, \n",
    "            verbose=0\n",
    "            #, n_jobs=nworkers if nworkers != 0 else None,\n",
    "        )\n",
    "grid_search.fit(z_norm, y_b, sample_weight=w_b)\n",
    "best_svm = grid_search.best_estimator_\n",
    "pd.DataFrame(grid_search.cv_results_).to_csv(\"cv_result_.csv\")\n",
    "\n",
    "best_C = grid_search.best_params_['C']\n",
    "best_g = grid_search.best_params_['gamma']\n",
    "\n",
    "y_sub = best_svm.predict(z_norm)\n",
    "\n",
    "aux = confusion_matrix(y_b, y_sub)\n",
    "print(\"Best C\", best_C)\n",
    "print(\"Best gamma\", best_g)\n",
    "print(aux)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are all elements close within the tolerance level:  True\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.12.3 64-bit' requires notebook and jupyter package.\n",
      "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
      "Command: 'python -m pip install jupyter notebook -U\n",
      "or\n",
      "conda install jupyter notebook -U'\n",
      "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "z_norm_M = pd.read_csv('./data/z_norm_M.csv', header=None, dtype=np.float64)\n",
    "z_norm_P = pd.read_csv('z_f.csv', header=None, dtype=np.float64)\n",
    "\n",
    "tolerance = 1e-10\n",
    "are_close = np.isclose(z_norm_M.values, z_norm_P.values, atol=tolerance)\n",
    "results = are_close.all()\n",
    "\n",
    "print(\"Are all elements close within the tolerance level: \", results)\n",
    "if not results:\n",
    "    mismatches = np.where(~are_close)\n",
    "    print(\"Mismatch found at positions:\", mismatches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.12.3 64-bit' requires notebook and jupyter package.\n",
      "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
      "Command: 'python -m pip install jupyter notebook -U\n",
      "or\n",
      "conda install jupyter notebook -U'\n",
      "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "def fit_libsvm(z, y, kkv, kernel_given):\n",
    "    accuracy= dict()\n",
    "    for k, v in kkv.items():\n",
    "        train_index, test_index = v[0], v[1]\n",
    "        # prepare training data\n",
    "        x_train = [z[i] for i in train_index]\n",
    "        y_train = [y[i] for i in train_index]\n",
    "        # prepare test data\n",
    "        x_test = [z[i] for i in test_index]\n",
    "        y_test = [y[i] for i in test_index]\n",
    "        svm = SVC(kernel=kernel_given, C=1.0, random_state = 0)\n",
    "        svm.fit(x_train, y_train)\n",
    "        y_pred = svm.predict(x_test)\n",
    "        # calculate accuracy\n",
    "        accuracy[k] = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_matsvm(z, y, w, skf, kernel_given, params):\n",
    "    # TODO Set up parallel workers in pool\n",
    "    \n",
    "\n",
    "    # Scikit-learn lib need to ensuring data contiguity\n",
    "    z = np.ascontiguousarray(z)\n",
    "    y = np.ascontiguousarray(y)\n",
    "    w = np.ascontiguousarray(w)\n",
    "    \n",
    "    # Check if hyperparameter is given by user\n",
    "    if(np.isnan(params)):\n",
    "\n",
    "        # Initialize a random number generator\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # Retrieve default hyperparameters for fitcsvm and sets the range for the box constraint (C) and kernel scale\n",
    "        # Define the range for C and gamma in a logarithmic scale\n",
    "        param_grid = {\n",
    "        'C': np.logspace(-10, 4, base=2, num=30),\n",
    "        'gamma': np.logspace(-10, 4, base=2, num=30)\n",
    "        }\n",
    "\n",
    "        # By default, the class_weight=None represent equal weight\n",
    "        svm_model = SVC(kernel=kernel_given, class_weight=None, random_state=0)\n",
    "\n",
    "        # steps = list()\n",
    "        # steps.append(('scaler', StandardScaler()))\n",
    "        # steps.append(('model', svm_model))\n",
    "        # pipeline = Pipeline(steps=steps)\n",
    "\n",
    "        # Used for exhaustive search over specified parameter values for the SVM. The param_grid defines \n",
    "        # the range over which C and gamma will be tuned.\n",
    "        # GridSearchCV for optimizing the hyperparameters\n",
    "\n",
    "        # TODO different c and gamma, same k-fold\n",
    "        # Unaltimate \n",
    "        grid_search = GridSearchCV(\n",
    "            svm_model, param_grid, \n",
    "            scoring='accuracy', # 'roc_auc' 'accuracy'\n",
    "            cv=skf, \n",
    "            verbose=0\n",
    "            #, n_jobs=nworkers if nworkers != 0 else None,\n",
    "            )\n",
    "        grid_search.fit(z, y, sample_weight=w)\n",
    "        best_svm = grid_search.best_estimator_\n",
    "        pd.DataFrame(grid_search.cv_results_).to_csv(\"cv_result_.csv\")\n",
    "\n",
    "        best_C = grid_search.best_params_['C']\n",
    "        best_g = grid_search.best_params_['gamma']\n",
    "        \n",
    "        # best_svm = SVC(kernel=kernel_given,C=best_C, gamma=best_g, class_weight=None, random_state=0)\n",
    "\n",
    "        # accuracy = np.zeros(skf.n_splits)\n",
    "        # for i, (train_index, test_index) in enumerate(skf.split(z,y)):\n",
    "        #     z_train, z_test = z[train_index], z[test_index]\n",
    "        #     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        #     best_svm.fit(z_train,y_train)\n",
    "\n",
    "        #     # Show the prediction accuracy\n",
    "        #     y_pred = best_svm.predict(z_test)\n",
    "        #     accuracy[i] = accuracy_score(y_test, y_pred)\n",
    "        # print(f\"mean accuracy is {np.mean(accuracy)}\")\n",
    "    \n",
    "        # OPT1: \n",
    "        # Fit a probability calibration model with trained SVM\n",
    "        # print(z.shape, y.shape, w.shape)\n",
    "        calibrator = CalibratedClassifierCV(best_svm, cv='prefit', method='sigmoid')\n",
    "        calibrator.fit(z, y, sample_weight=w)\n",
    "\n",
    "        # OPT2: retrain\n",
    "        # calibrator = CalibratedClassifierCV(best_svm, cv=skf, method='sigmoid')\n",
    "        # calibrator.fit(z_norm, y, sample_weight=w)\n",
    "\n",
    "        best_C = grid_search.best_params_['C']\n",
    "        best_g = grid_search.best_params_['gamma']\n",
    "\n",
    "        y_sub = best_svm.predict(z)\n",
    "        p_sub = calibrator.predict_proba(z)\n",
    "\n",
    "        # Making predictions on the same data to simulate resubstitution prediction\n",
    "        y_hat = y_sub\n",
    "        p_hat = p_sub\n",
    "        \n",
    "        print(\"Best C:\", best_C)\n",
    "        print(\"Best gamma:\", best_g)\n",
    "\n",
    "\n",
    "    return best_svm, y_sub, p_sub, y_hat, p_hat, best_C, best_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATSVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 1.1003260089454092\n",
      "Best gamma: 11.449727669768906\n",
      "[[ 73  10]\n",
      " [  2 127]]\n",
      "    -> PYTHIA has trained a model for NB, there are 9 models left to train.\n",
      "      -> Elapsed time: 19.08s\n",
      "Best C: 3.0025887646926703\n",
      "Best gamma: 0.014200336875591593\n",
      "[[ 59  25]\n",
      " [ 10 118]]\n",
      "    -> PYTHIA has trained a model for LDA, there are 8 models left to train.\n",
      "      -> Elapsed time: 18.88s\n",
      "Best C: 1.1003260089454092\n",
      "Best gamma: 0.05414993620051815\n",
      "[[118  19]\n",
      " [ 21  54]]\n",
      "    -> PYTHIA has trained a model for QDA, there are 7 models left to train.\n",
      "      -> Elapsed time: 18.38s\n",
      "Best C: 11.449727669768906\n",
      "Best gamma: 0.010161874377781294\n",
      "[[ 54   7]\n",
      " [  9 142]]\n",
      "    -> PYTHIA has trained a model for CART, there are 6 models left to train.\n",
      "      -> Elapsed time: 16.66s\n",
      "Best C: 4.195857021292137\n",
      "Best gamma: 0.0756698328726082\n",
      "[[ 50   8]\n",
      " [ 10 144]]\n",
      "    -> PYTHIA has trained a model for J48, there are 5 models left to train.\n",
      "      -> Elapsed time: 16.53s\n",
      "Best C: 1.537610033259584\n",
      "Best gamma: 0.10574201945068336\n",
      "[[ 51   7]\n",
      " [  9 145]]\n",
      "    -> PYTHIA has trained a model for KNN, there are 4 models left to train.\n",
      "      -> Elapsed time: 16.54s\n",
      "Best C: 4.195857021292137\n",
      "Best gamma: 0.014200336875591593\n",
      "[[ 51  10]\n",
      " [  7 144]]\n",
      "    -> PYTHIA has trained a model for L_SVM, there are 3 models left to train.\n",
      "      -> Elapsed time: 16.75s\n",
      "Best C: 16.0\n",
      "Best gamma: 0.010161874377781294\n",
      "[[86 14]\n",
      " [14 98]]\n",
      "    -> PYTHIA has trained a model for poly_SVM, there are 2 models left to train.\n",
      "      -> Elapsed time: 18.99s\n",
      "Best C: 8.193516481991983\n",
      "Best gamma: 0.02772989967235997\n",
      "[[ 57   5]\n",
      " [  7 143]]\n",
      "    -> PYTHIA has trained a model for RBF_SVM, there are 1 models left to train.\n",
      "      -> Elapsed time: 16.78s\n",
      "Best C: 3.0025887646926703\n",
      "Best gamma: 0.038750126426955855\n",
      "[[ 48  19]\n",
      " [  8 137]]\n",
      "    -> PYTHIA has trained a model for RandF, there are 0 models left to train.\n",
      "      -> Elapsed time: 17.67s\n"
     ]
    }
   ],
   "source": [
    "t = TicToc()\n",
    "t.tic()\n",
    "# skf = StratifiedKFold(n_splits = opts_csv_fold, shuffle=True, random_state=0)\n",
    "\n",
    "for i in range(nalgos):\n",
    "    t_inner = TicToc()\n",
    "    t_inner.tic()\n",
    "\n",
    "    state = np.random.get_state()\n",
    "    np.random.seed(0)  # equivalent to MATLAB's rng('default') ?\n",
    "\n",
    "    # y_b = [row[i] for row in y]\n",
    "    y_b = y[:, i]\n",
    "\n",
    "    # Problem: Not exactly the same for each run ?????\n",
    "    # https://stackoverflow.com/questions/73527928/does-stratifiedkfold-splits-the-same-each-time-a-for-loop-is-called\n",
    "    skf = StratifiedKFold(n_splits = opts_csv_fold, shuffle=True, random_state=0)\n",
    "    # skf = KFold(n_splits = opts_csv_fold, shuffle = True, random_state = 0)\n",
    "\n",
    "    # fit_matsvm(z_norm, y_b, w[:, i], skf, kernel_fcn, np.nan)\n",
    "\n",
    "    best_svm, y_sub, p_sub, y_hat, p_hat, best_C, best_g = fit_matsvm(z_norm, y_b, w[:, i], skf, kernel_fcn, np.nan)\n",
    "    aux = confusion_matrix(y_b, y_sub)\n",
    "    print(aux)\n",
    "    # np.prod(aux.shape) != 4 is False\n",
    "    cvcmat[i, :] = aux.flatten()\n",
    "\n",
    "    models_left = nalgos - (i + 1)\n",
    "    print(f\"    -> PYTHIA has trained a model for {algo_labels[i]}, there are {models_left} models left to train.\")\n",
    "\n",
    "    print(f\"      -> Elapsed time: {t_inner.tocvalue():.2f}s\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "[ 73.  59. 118.  54.  50.  51.  51.  86.  57.  48.]\n",
      "[0.9270073  0.82517483 0.73972603 0.95302013 0.94736842 0.95394737\n",
      " 0.93506494 0.875      0.96621622 0.87820513]\n",
      "[0.98449612 0.921875   0.72       0.94039735 0.93506494 0.94155844\n",
      " 0.95364238 0.875      0.95333333 0.94482759]\n",
      "[0.94339623 0.83490566 0.81132075 0.9245283  0.91509434 0.9245283\n",
      " 0.91981132 0.86792453 0.94339623 0.87264151]\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "tn, fp, fn, tp = cvcmat[:, 0], cvcmat[:, 1], cvcmat[:, 2], cvcmat[:, 3]\n",
    "print(tn.dtype)  \n",
    "print(tn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "accuracy = (tp + tn) / ninst\n",
    "\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIBSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold: accuracy score = 0.8837209302325582\n",
      "1 fold: accuracy score = 0.9047619047619048\n",
      "2 fold: accuracy score = 0.8333333333333334\n",
      "3 fold: accuracy score = 0.8333333333333334\n",
      "4 fold: accuracy score = 0.8571428571428571\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.12.3 64-bit' requires notebook and jupyter package.\n",
      "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
      "Command: 'python -m pip install jupyter notebook -U\n",
      "or\n",
      "conda install jupyter notebook -U'\n",
      "Click <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "y = pd.read_csv('./data/ybin.csv')\n",
    "y = y.values.tolist()\n",
    "\n",
    "z = pd.read_csv('./data/z.csv').values.tolist()\n",
    "z_norm = zscore(z, axis = 0, ddof = 1)\n",
    "\n",
    "for i in range(nalgos):\n",
    "    t_inner = TicToc()\n",
    "    t_inner.tic()\n",
    "\n",
    "    state = np.random.get_state()\n",
    "    np.random.seed(0)  # equivalent to MATLAB's rng('default') ?\n",
    "\n",
    "    # REQUIRE: Test case for validation the result\n",
    "    y_b = [row[i] for row in y]\n",
    "    # y_b = y[:, i]\n",
    "    skf = StratifiedKFold(n_splits = opts_csv_fold, shuffle = True, random_state = 0)\n",
    "    \n",
    "    kkv= dict()\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(np.zeros(len(y_b)), y_b)):\n",
    "        kkv[i] = [train_index.tolist(), test_index.tolist()]\n",
    "    \n",
    "    # start training using svm\n",
    "    svm_res = fit_libsvm(z_norm, y_b, kkv, kernel_fcn)\n",
    "\n",
    "    # visualise accuracy score\n",
    "for k, v in svm_res.items():\n",
    "    print(f'{k} fold: accuracy score = {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FITLIBSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8d4e9334dcc093c5455b6f55ea09f9028125097d0b5d072b5d027a0ea5ecbe2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
