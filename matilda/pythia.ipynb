{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library used and deeclare data needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from numpy.typing import NDArray\n",
    "from scipy.stats import zscore\n",
    "from pytictoc import TicToc\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from matilda.data.model import AlgorithmSummary\n",
    "# from matilda.data.option import Opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_fcn = 'rbf'\n",
    "opts_csv_fold = 5\n",
    "with open('./data/algolabels.csv', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            algo_labels = row\n",
    "\n",
    "# prepare for y, transpose it\n",
    "# y = pd.read_csv('./data/ybin.csv')\n",
    "# y = y.values.tolist()\n",
    "\n",
    "y = np.loadtxt('./data/ybin.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "# prepare for z, normalise it\n",
    "z = pd.read_csv('./data/z.csv')\n",
    "z_norm = zscore(z, axis = 0, ddof = 1)\n",
    "\n",
    "ninst, nalgos = y.shape\n",
    "w = np.ones((ninst, nalgos))\n",
    "\n",
    "cvcmat = np.zeros((nalgos, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_libsvm(z, y, kkv, kernel_given):\n",
    "    accuracy= dict()\n",
    "    for k, v in kkv.items():\n",
    "        train_index, test_index = v[0], v[1]\n",
    "        # prepare training data\n",
    "        x_train = [z[i] for i in train_index]\n",
    "        y_train = [y[i] for i in train_index]\n",
    "        # prepare test data\n",
    "        x_test = [z[i] for i in test_index]\n",
    "        y_test = [y[i] for i in test_index]\n",
    "        svm = SVC(kernel=kernel_given, C=1.0, random_state = 0)\n",
    "        svm.fit(x_train, y_train)\n",
    "        y_pred = svm.predict(x_test)\n",
    "        # calculate accuracy\n",
    "        accuracy[k] = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_matsvm(z, y, w, skf, kernel_given, params):\n",
    "    # Set up parallel workers in pool\n",
    "    \n",
    "    # Check if hyperparameter is given by user\n",
    "    if(np.isnan(params)):\n",
    "        # Initialize a random number generator\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # Scikit-learn lib need to ensuring data contiguity\n",
    "        z = np.ascontiguousarray(z)\n",
    "        y = np.ascontiguousarray(y)\n",
    "        w = np.ascontiguousarray(w)\n",
    "\n",
    "        # Debug shape and data type\n",
    "        # print(w.flags)\n",
    "\n",
    "        # Retrieve default hyperparameters for fitcsvm and sets the range for the box constraint (C) and kernel scale\n",
    "        # Define the range for C and gamma in a logarithmic scale\n",
    "        param_grid = {\n",
    "        # Generates 15 numbers between 2^-10 and 2^4\n",
    "        'C': np.logspace(-10, 4, base=2, num=15),\n",
    "        'gamma': np.logspace(-10, 4, base=2, num=15)  \n",
    "        }\n",
    "\n",
    "        # cache_size: maximal, ?????class_weight='balanced'\n",
    "        svm_model = SVC(kernel=kernel_given, cache_size=2000, class_weight='balanced', probability=True)\n",
    "\n",
    "        # Used for exhaustive search over specified parameter values for the SVM. The param_grid defines \n",
    "        # the range over which C and gamma will be tuned.\n",
    "        # GridSearchCV for optimizing the hyperparameters\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=svm_model, \n",
    "            param_grid=param_grid, \n",
    "            # 'roc_auc' measures the area under the receiver operating characteristic curve, which is a \n",
    "            # good choice for binary classification problems, especially with imbalanced classes.\n",
    "            scoring='roc_auc', \n",
    "            cv=skf, \n",
    "            verbose=0\n",
    "            #, n_jobs=nworkers if nworkers != 0 else None,\n",
    "            )\n",
    "\n",
    "        # Fit GridSearchCV\n",
    "        grid_search.fit(z, y, sample_weight=w)\n",
    "\n",
    "        # Retrieve the best model and hyperparameters\n",
    "        best_svm = grid_search.best_estimator_\n",
    "        best_C = grid_search.best_params_['C']\n",
    "        best_g = grid_search.best_params_['gamma']\n",
    "\n",
    "        # Calibrate the probability model\n",
    "        calibrated_svm = CalibratedClassifierCV(best_svm, cv='prefit')\n",
    "        calibrated_svm.fit(z, y, sample_weight=w)\n",
    "        \n",
    "        # Making predictions on the training data\n",
    "        y_sub = calibrated_svm.predict(z)\n",
    "        p_sub = calibrated_svm.predict_proba(z)[:, 1]\n",
    "\n",
    "        t_y_sub = best_svm.predict(z)\n",
    "        t_p_sub = best_svm.predict_proba(z)[:, 1]\n",
    "\n",
    "        # Making predictions on the same data to simulate resubstitution prediction\n",
    "        y_hat = y_sub\n",
    "        p_hat = p_sub\n",
    "        \n",
    "        print(\"svm: \", calibrated_svm)\n",
    "        print(\"Best C:\", best_C)\n",
    "        print(\"Best gamma:\", best_g)\n",
    "\n",
    "\n",
    "    return calibrated_svm, y_sub #, p_sub, y_hat, p_hat, best_C, best_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATSVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm:  CalibratedClassifierCV(cv='prefit',\n",
      "                       estimator=SVC(C=8.0, cache_size=2000,\n",
      "                                     class_weight='balanced', gamma=0.0078125,\n",
      "                                     probability=True))\n",
      "Best C: 8.0\n",
      "Best gamma: 0.0078125\n",
      "------------aux-----------\n",
      "[[ 65  17]\n",
      " [ 16 113]]\n",
      "    -> PYTHIA has trained a model for NB, there are 9 models left to train.\n",
      "      -> Elapsed time: 16.15s\n",
      "svm:  CalibratedClassifierCV(cv='prefit',\n",
      "                       estimator=SVC(C=16.0, cache_size=2000,\n",
      "                                     class_weight='balanced', gamma=0.5,\n",
      "                                     probability=True))\n",
      "Best C: 16.0\n",
      "Best gamma: 0.5\n",
      "------------aux-----------\n",
      "[[ 63  20]\n",
      " [ 10 118]]\n",
      "    -> PYTHIA has trained a model for LDA, there are 8 models left to train.\n",
      "      -> Elapsed time: 16.77s\n",
      "svm:  CalibratedClassifierCV(cv='prefit',\n",
      "                       estimator=SVC(C=8.0, cache_size=2000,\n",
      "                                     class_weight='balanced', gamma=0.0625,\n",
      "                                     probability=True))\n",
      "Best C: 8.0\n",
      "Best gamma: 0.0625\n",
      "------------aux-----------\n",
      "[[111  25]\n",
      " [ 22  53]]\n",
      "    -> PYTHIA has trained a model for QDA, there are 7 models left to train.\n",
      "      -> Elapsed time: 25.52s\n",
      "svm:  CalibratedClassifierCV(cv='prefit',\n",
      "                       estimator=SVC(C=16.0, cache_size=2000,\n",
      "                                     class_weight='balanced', gamma=0.125,\n",
      "                                     probability=True))\n",
      "Best C: 16.0\n",
      "Best gamma: 0.125\n",
      "------------aux-----------\n",
      "[[ 54   6]\n",
      " [  8 143]]\n",
      "    -> PYTHIA has trained a model for CART, there are 6 models left to train.\n",
      "      -> Elapsed time: 26.78s\n",
      "svm:  CalibratedClassifierCV(cv='prefit',\n",
      "                       estimator=SVC(C=16.0, cache_size=2000,\n",
      "                                     class_weight='balanced', gamma=0.0625,\n",
      "                                     probability=True))\n",
      "Best C: 16.0\n",
      "Best gamma: 0.0625\n",
      "------------aux-----------\n",
      "[[ 48   9]\n",
      " [  9 145]]\n",
      "    -> PYTHIA has trained a model for J48, there are 5 models left to train.\n",
      "      -> Elapsed time: 26.14s\n",
      "svm:  CalibratedClassifierCV(cv='prefit',\n",
      "                       estimator=SVC(C=8.0, cache_size=2000,\n",
      "                                     class_weight='balanced', gamma=0.125,\n",
      "                                     probability=True))\n",
      "Best C: 8.0\n",
      "Best gamma: 0.125\n",
      "------------aux-----------\n",
      "[[ 51   6]\n",
      " [  7 147]]\n",
      "    -> PYTHIA has trained a model for KNN, there are 4 models left to train.\n",
      "      -> Elapsed time: 26.68s\n",
      "svm:  CalibratedClassifierCV(cv='prefit',\n",
      "                       estimator=SVC(C=8.0, cache_size=2000,\n",
      "                                     class_weight='balanced', gamma=0.0625,\n",
      "                                     probability=True))\n",
      "Best C: 8.0\n",
      "Best gamma: 0.0625\n",
      "------------aux-----------\n",
      "[[ 54   6]\n",
      " [  7 144]]\n",
      "    -> PYTHIA has trained a model for L_SVM, there are 3 models left to train.\n",
      "      -> Elapsed time: 22.89s\n",
      "svm:  CalibratedClassifierCV(cv='prefit',\n",
      "                       estimator=SVC(C=16.0, cache_size=2000,\n",
      "                                     class_weight='balanced', gamma=0.015625,\n",
      "                                     probability=True))\n",
      "Best C: 16.0\n",
      "Best gamma: 0.015625\n",
      "------------aux-----------\n",
      "[[85 14]\n",
      " [14 98]]\n",
      "    -> PYTHIA has trained a model for poly_SVM, there are 2 models left to train.\n",
      "      -> Elapsed time: 15.68s\n",
      "svm:  CalibratedClassifierCV(cv='prefit',\n",
      "                       estimator=SVC(C=2.0, cache_size=2000,\n",
      "                                     class_weight='balanced', gamma=0.125,\n",
      "                                     probability=True))\n",
      "Best C: 2.0\n",
      "Best gamma: 0.125\n",
      "------------aux-----------\n",
      "[[ 54   7]\n",
      " [  7 143]]\n",
      "    -> PYTHIA has trained a model for RBF_SVM, there are 1 models left to train.\n",
      "      -> Elapsed time: 15.02s\n",
      "svm:  CalibratedClassifierCV(cv='prefit',\n",
      "                       estimator=SVC(C=16.0, cache_size=2000,\n",
      "                                     class_weight='balanced', gamma=0.03125,\n",
      "                                     probability=True))\n",
      "Best C: 16.0\n",
      "Best gamma: 0.03125\n",
      "------------aux-----------\n",
      "[[ 48  18]\n",
      " [ 12 133]]\n",
      "    -> PYTHIA has trained a model for RandF, there are 0 models left to train.\n",
      "      -> Elapsed time: 15.90s\n",
      "float64\n",
      "[ 65.  63. 111.  54.  48.  51.  54.  85.  54.  48.]\n"
     ]
    }
   ],
   "source": [
    "t = TicToc()\n",
    "t.tic()\n",
    "\n",
    "for i in range(nalgos):\n",
    "    t_inner = TicToc()\n",
    "    t_inner.tic()\n",
    "\n",
    "    state = np.random.get_state()\n",
    "    np.random.seed(0)  # equivalent to MATLAB's rng('default') ?\n",
    "\n",
    "    # REQUIRE: Test case for validation the result\n",
    "    # y_b = [row[i] for row in y]\n",
    "    y_b = y[:, i]\n",
    "    skf = StratifiedKFold(n_splits = opts_csv_fold, shuffle = True, random_state = 0)\n",
    "    \n",
    "    # kkv= dict()\n",
    "    # for i, (train_index, test_index) in enumerate(skf.split(np.zeros(len(y_b)), y_b)):\n",
    "    #     kkv[i] = [train_index.tolist(), test_index.tolist()]\n",
    "    # start training using svm\n",
    "    # svm_res = fit_libsvm(z_norm, y_b, kkv, kernel_fcn)\n",
    "    \n",
    "    svm_res, y_sub = fit_matsvm(z_norm, y_b, w[:, i], skf, kernel_fcn, np.nan)\n",
    "    aux = confusion_matrix(y_b, y_sub)\n",
    "    print(\"------------aux-----------\")\n",
    "    print(aux)\n",
    "    # 66    17   16   113\n",
    "\n",
    "    # np.prod(aux.shape) != 4 is False\n",
    "    cvcmat[i, :] = aux.flatten()\n",
    "    models_left = nalgos - (i + 1)\n",
    "    print(f\"    -> PYTHIA has trained a model for {algo_labels[i]}, there are {models_left} models left to train.\")\n",
    "\n",
    "    print(f\"      -> Elapsed time: {t_inner.tocvalue():.2f}s\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "[ 65.  63. 111.  54.  48.  51.  54.  85.  54.  48.]\n",
      "[0.86923077 0.85507246 0.67948718 0.95973154 0.94155844 0.96078431\n",
      " 0.96       0.875      0.95333333 0.8807947 ]\n",
      "[0.87596899 0.921875   0.70666667 0.94701987 0.94155844 0.95454545\n",
      " 0.95364238 0.875      0.95333333 0.91724138]\n",
      "[0.8436019  0.85781991 0.77725118 0.93364929 0.91469194 0.93838863\n",
      " 0.93838863 0.86729858 0.93364929 0.85781991]\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "tn, fp, fn, tp = cvcmat[:, 0], cvcmat[:, 1], cvcmat[:, 2], cvcmat[:, 3]\n",
    "print(tn.dtype)  \n",
    "print(tn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "accuracy = (tp + tn) / ninst\n",
    "\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIBSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold: accuracy score = 0.8837209302325582\n",
      "1 fold: accuracy score = 0.9047619047619048\n",
      "2 fold: accuracy score = 0.8333333333333334\n",
      "3 fold: accuracy score = 0.8333333333333334\n",
      "4 fold: accuracy score = 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "y = pd.read_csv('./data/ybin.csv')\n",
    "y = y.values.tolist()\n",
    "\n",
    "z = pd.read_csv('./data/z.csv').values.tolist()\n",
    "z_norm = zscore(z, axis = 0, ddof = 1)\n",
    "\n",
    "for i in range(nalgos):\n",
    "    t_inner = TicToc()\n",
    "    t_inner.tic()\n",
    "\n",
    "    state = np.random.get_state()\n",
    "    np.random.seed(0)  # equivalent to MATLAB's rng('default') ?\n",
    "\n",
    "    # REQUIRE: Test case for validation the result\n",
    "    y_b = [row[i] for row in y]\n",
    "    # y_b = y[:, i]\n",
    "    skf = StratifiedKFold(n_splits = opts_csv_fold, shuffle = True, random_state = 0)\n",
    "    \n",
    "    kkv= dict()\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(np.zeros(len(y_b)), y_b)):\n",
    "        kkv[i] = [train_index.tolist(), test_index.tolist()]\n",
    "    \n",
    "    # start training using svm\n",
    "    svm_res = fit_libsvm(z_norm, y_b, kkv, kernel_fcn)\n",
    "\n",
    "    # visualise accuracy score\n",
    "for k, v in svm_res.items():\n",
    "    print(f'{k} fold: accuracy score = {v}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8d4e9334dcc093c5455b6f55ea09f9028125097d0b5d072b5d027a0ea5ecbe2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.19 ('new_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
